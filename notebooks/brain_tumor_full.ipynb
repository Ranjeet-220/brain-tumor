{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Brain Tumor Detection - Complete Pipeline\n",
                "\n",
                "This notebook contains the complete code for Data Downloading, Preprocessing, Model Definition, and Training for the Brain Tumor Detection system.\n",
                "You can run this directly in Google Colab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install kagglehub tensorflow opencv-python matplotlib scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Download Dataset\n",
                "import kagglehub\n",
                "import shutil\n",
                "import os\n",
                "\n",
                "def download_and_setup_data():\n",
                "    print(\"Downloading dataset...\")\n",
                "    path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
                "    print(\"Path to dataset files:\", path)\n",
                "    \n",
                "    # Define target path\n",
                "    target_path = os.path.join(os.getcwd(), \"data\", \"real\")\n",
                "    \n",
                "    # Clean previous real data if exists\n",
                "    if os.path.exists(target_path):\n",
                "        shutil.rmtree(target_path)\n",
                "    \n",
                "    # Copy to project directory\n",
                "    print(f\"Copying to {target_path}...\")\n",
                "    shutil.copytree(path, target_path)\n",
                "    print(\"Dataset setup complete.\")\n",
                "\n",
                "download_and_setup_data()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Imports\n",
                "import os\n",
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "from sklearn.model_selection import train_test_split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Preprocessing Functions\n",
                "def load_data(data_dir, img_size=(224, 224)):\n",
                "    \"\"\"\n",
                "    Loads images from the data directory.\n",
                "    Assumes structure:\n",
                "    data_dir/\n",
                "        glioma/\n",
                "        meningioma/\n",
                "        notumor/\n",
                "        pituitary/\n",
                "    Maps to Binary: 0 (No Tumor), 1 (Tumor)\n",
                "    \"\"\"\n",
                "    # Map directory names to binary labels\n",
                "    # notumor -> 0\n",
                "    # others -> 1\n",
                "    categories = ['notumor', 'glioma', 'meningioma', 'pituitary']\n",
                "    \n",
                "    data = []\n",
                "    labels = []\n",
                "    \n",
                "    for category in categories:\n",
                "        path = os.path.join(data_dir, category)\n",
                "        \n",
                "        # Determine label\n",
                "        if category == 'notumor':\n",
                "            binary_label = 0\n",
                "        else:\n",
                "            binary_label = 1\n",
                "        \n",
                "        if not os.path.exists(path):\n",
                "            print(f\"Warning: Directory {path} does not exist. Skipping...\")\n",
                "            continue\n",
                "            \n",
                "        print(f\"Loading {category}...\")\n",
                "        for img_name in os.listdir(path):\n",
                "            try:\n",
                "                img_path = os.path.join(path, img_name)\n",
                "                img_array = cv2.imread(img_path)\n",
                "                if img_array is None:\n",
                "                    continue\n",
                "                new_array = cv2.resize(img_array, img_size)\n",
                "                data.append(new_array)\n",
                "                labels.append(binary_label)\n",
                "            except Exception as e:\n",
                "                pass\n",
                "                \n",
                "    return np.array(data), np.array(labels)\n",
                "\n",
                "def preprocess_data(data, labels):\n",
                "    \"\"\"\n",
                "    Normalizes data and converts labels to categorical.\n",
                "    \"\"\"\n",
                "    # Normalize pixel values to [0, 1]\n",
                "    data = data / 255.0\n",
                "    \n",
                "    # Convert labels to numpy array if not already\n",
                "    labels = np.array(labels)\n",
                "    \n",
                "    return data, labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Model Definition\n",
                "def build_model(input_shape=(224, 224, 3)):\n",
                "    model = Sequential([\n",
                "        # Convolutional Layer 1\n",
                "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
                "        MaxPooling2D((2, 2)),\n",
                "        \n",
                "        # Convolutional Layer 2\n",
                "        Conv2D(64, (3, 3), activation='relu'),\n",
                "        MaxPooling2D((2, 2)),\n",
                "        \n",
                "        # Convolutional Layer 3\n",
                "        Conv2D(128, (3, 3), activation='relu'),\n",
                "        MaxPooling2D((2, 2)),\n",
                "        \n",
                "        # Flattening\n",
                "        Flatten(),\n",
                "        \n",
                "        # Fully Connected Layer\n",
                "        Dense(128, activation='relu'),\n",
                "        Dropout(0.5), # Add dropout to prevent overfitting\n",
                "        \n",
                "        # Output Layer (Binary Classification: Tumor vs No Tumor)\n",
                "        Dense(1, activation='sigmoid') \n",
                "    ])\n",
                "    \n",
                "    model.compile(optimizer='adam',\n",
                "                  loss='binary_crossentropy',\n",
                "                  metrics=['accuracy'])\n",
                "    \n",
                "    return model\n",
                "\n",
                "model = build_model()\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Training Pipeline\n",
                "def train_pipeline():\n",
                "    # Load and preprocess data\n",
                "    # In Colab/Monolithic, the path is relative to where we downloaded it\n",
                "    raw_path = \"data/real/Training\"\n",
                "    print(\"Loading data...\")\n",
                "    X, y = load_data(raw_path)\n",
                "    \n",
                "    if len(X) == 0:\n",
                "        print(\"No data found. Please place images in data/real/Training\")\n",
                "        return\n",
                "\n",
                "    print(f\"Data loaded: {len(X)} samples\")\n",
                "    X, y = preprocess_data(X, y)\n",
                "    \n",
                "    # Split data\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "    \n",
                "    # Build model\n",
                "    model = build_model()\n",
                "    \n",
                "    # Callbacks\n",
                "    checkpoint_path = \"brain_tumor_model.keras\"\n",
                "    \n",
                "    callbacks = [\n",
                "        tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss'),\n",
                "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
                "    ]\n",
                "    \n",
                "    # Train\n",
                "    print(\"Starting training...\")\n",
                "    history = model.fit(\n",
                "        X_train, y_train,\n",
                "        epochs=20, \n",
                "        batch_size=32, \n",
                "        validation_data=(X_test, y_test),\n",
                "        callbacks=callbacks\n",
                "    )\n",
                "    \n",
                "    print(\"Training complete.\")\n",
                "    \n",
                "    # Evaluate\n",
                "    loss, accuracy = model.evaluate(X_test, y_test)\n",
                "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
                "    \n",
                "    return history, model\n",
                "\n",
                "history, model = train_pipeline()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Visualization\n",
                "plt.plot(history.history['accuracy'], label='accuracy')\n",
                "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.ylim([0.5, 1])\n",
                "plt.legend(loc='lower right')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}